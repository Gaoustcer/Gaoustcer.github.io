---
layout:     post
title:      数据隐私的方法伦理与实践——实验一实验报告
subtitle:   Data Privacy
date:       2021-06-11
author:     Haihan Gao
header-img: img/post-bg-swift2.jpg
catalog: true
tags:
    - Machine Learning
    - Data Privacy
---
# 数据隐私的方法伦理与实践实验一实验报告

**PB18030980**

## 实验目的

* 设计算法，分别从全局泛化和cell级别的泛化得到满足k匿名的表
* 计算泛化之后得到的表的LM
* 体会允许suppression和不允许suppression对LM的影响

## 实验内容

### Samarati算法

采用全局泛化，一个一般的思想是如果泛化层次比较低那么信息损失会比较少，这个算法采取二分算法求取最小泛化层次

### Mondrian算法

采用局部泛化，对于一个表，对其字段采取二分的方式进行泛化，对于不满足泛化条件K匿名的子表，就将按照字段的上下界直接泛化

## Samarati算法(在Samarati文件夹下)

### 执行环境

python 3.8以上

Windows10操作系统

数据集

### 执行方式

进入`Samarati`文件夹下，执行

```shell
python samarati.py
```

会在同一个文件夹下生成一个文件名为`output.csv`的脱敏后的数据，并在屏幕上打印出LM向量

![image-20210515172216670](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515172216670.png)

### 代码结构说明

含有多个文件，下面说明每个文件的功能

* `adult.csv`是源数据文件，转化为了csv的形式
* `dataread.py`读入csv源数据文件的模块，删除包含`?`的行
* `general.py`按照泛化向量进行泛化，或者根据生成的数值化泛化表反演出原表，操作的对象是表的每一行(以一个元组传入)
* `datacut.py`对非数值属性进行编码数值化，并取原表中的QI-cluster和敏感属性两列
* `judge.py`对于一个输入的泛化之后的表，判断其是否满足k匿名
* `samarati.py`是顶层模块，调用其它模块内的函数，输出泛化后的表，并计算loss_metric

### 算法基本思路

1. 从文件读入数据
2. 取表的QI-cluster和sensitive attribute，并向量化
3. 设low=0，high=8
4. middle=$\frac{(low+high)}{2}$
5. 判断泛化到middle层能否满足k匿名
   1. 如果可以，则low=middle
   2. 不行，high=middle
   3. 直到high$\leq$low,算法结束，返回泛化方案和删除的向量集合
6. 回到第四步

### 模块函数说明

#### `dataread`

`readdata()`模块使用`read_csv`方法读入csv文件，对每一行进行遍历。如果该行含有？则将这一行的主键号加入一个列表`Not_complete`中，再调用`drop`方法删去这个列表中含有？的行，最后使用`reset_index`重新组织index，返回删去？的表

#### `datacut`

`datacut()`取`dataread` 输入，并且将非数值属性数值化方便计算Loss Metric，遍历每一行转换为数字

#### `general`

含有两个函数，`returngenresult`接受两个参数，均为list类型，一个为泛化向量`genvector`a$=[x_0,x_1,x_2,x_3,x_4]$ $x_1,x_2,x_3,x_4$分别对应的是原本数据中的`age,sex,race,martial_status`四种情况的泛化层次，`origin`是原本的数据集中数据列表，返回泛化的结果。

`returnoriginresult`相当于去数值化，将输入的泛化后的数据去数值化，在输出模块中应用

#### `judge`

`judgeandpick()`输出一个三元组，第一个是布尔变量，判断输入数据表是否满足k匿名，第二维是一个列表，存有需要删除的QI-cluster，第三个是一个数字，返回需要删除的条目总数

这个函数需要三个参数，原始数据表，k匿名的k参数，最大允许suppression的记录数目 

#### `datatrans`

`datatrans()`函数调用judge模块中的每一行，得到泛化后的整个表格并返回

#### `samarati`

`samarati`是主控模块，含有以下函数

* `getvaild_vector(level:int)`接收一个整型参数，相当于当前泛化的层次。返回满足这个层次的所有向量列表
* `lossmetric(DataFrame)`返回一个泛化得到的数值表LM向量
* `samarati_new`调用其它函数，实现了`samarati`算法
* `origin_table`接收数值化的泛化结果，返回原本的表

### 运行结果

#### 损失函数

![image-20210516153021669](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210516153021669.png)

#### 泛化之后的表

见output.csv文件

#### 执行时间

82s

## Mondrain算法

### 算法基本思想

采用分治的算法，逐步对表进行泛化，这里选择泛化结果的维度的顺序是：先尝试`age`属性，如果按照`age`属性分割表格不能实现k匿名，那么就选择`education_num`属性进行分割，如果两个属性分割均不能满足要求，就将表的各维度泛化输出

### 运行

进入`Mondrain`文件夹下，执行

```shell
python Mondrian.py
```

会生成一个泛化之后的表`Anoy.csv`存储的是泛化后的数据

### 文件结构

adult.csv是数据文件

dataread.py是数据读入和预处理单元

Mondrian.py是整个工程的主控模块

### Mondrian.py模块函数解析

* `whether_can_generation`共有三个参数，分别是被泛化的数据表，k匿名的k，以及按照什么维度泛化的字符串('age'或是'education_num'),如果不能按照这个维度泛化，返回false和两个空字典，如果可以，则返回True和两个字典，可以由这两个字典得到划分后的两个子表
* `Anonymize`参数是一个数据表和k匿名的参数k，返回一个列表，这个列表包含最终泛化结果的表集合
  * 对于输入的列表，分别按照'age'和'education_num'进行划分，如果有一个划分是满足k匿名的，就按照这个属性进行划分，否则意味着表已经被划分到了一个最小的粒度，需要进行泛化
  * 对于不可划分的表，进行泛化，求取每一列的最大最小值max和min，将每一列泛化为一个列表[min,max]，并将划分完的表打包在一个列表中返回
  * 对于可划分的列表，需要对其划分后的表继续泛化，划分的结果也就打包在一个列表中
* `Mondrian()`调用匿名化`Anonymize`函数，返回最终泛化生成的列表
* 主控部分，用一个cluster接收Mondrian函数返回的结果，用pandas.concat方法将这个列表拼接为一个表，再在一个表上求解loss_metric

### 执行结果

上面是LM向量，下面是LM各个维度之和

![image-20210516152806096](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210516152806096.png)

执行时间约为4s

## 扩展部分

### 找到最小的Samarati损失

查阅原本的论文，我们找到一个解决方案，因为不同属性之间存在语义不匹配性，最大泛化层次比较高的属性，我们对其进行少数全局泛化，得到的LM可能非常大，对于泛化到某个高度`height`,存在多个泛化向量$(x_1,x_2,x_3,x_4)$,假设对应的四个属性最大泛化高度为$h_1,h_2,h_3,h_4$，我们定义如下启发式函数，避免计算Loss-Metric能够事先判断出最优的损失函数

$F(x_1,x_2,x_3,x_4)=x_1\times h_1+x_2\times h_2+x_3\times h_3+x_4\times h_4$

F越小，则我们认为估计的Loss越小，在同一层中优先对F最小的层次进行搜索。

这里还有一个问题，假设Samarati得到的最小泛化高度为$min_h$，则在$min_h$高度之上的泛化层次可能仍然满足k匿名并且损失比较小，这就意味着需要对$min_h$以及以上高度的泛化方式进行遍历并且利用启发式进行判断

进入`extend_Samarti`下，执行samarati.py，运行结果如下

![image-20210515175413974](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515175413974.png)

### 对gender使用Mondrian算法

对Male和FeMale进行编码，Male编码为0，FeMale编码为1，再调用数值算法即可，算出来损失如下，`extend_Mondrian/extend_Mondrian.py`

![image-20210515175515879](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515175515879.png)

## K,Maxsuppression改变对于LM的影响

### Samarati

#### k=10

| Maxsuppression | Loss_Metricsum     |
| -------------- | ------------------ |
| 10             | 2.0552459640316716 |
| 20             | 2.0552459640316716 |
| 30             | 3.0008951661030436 |
| 40             | 3.0008951661030436 |
| 50             | 3.0008951661030436 |

相邻Maxsuppression之间损失差距不大，因为这里采取的是全局泛化，提高泛化层次必然出现大量不满足k-匿名的cluster，这样就会导致泛化到相同的层次可以满足不同的类型

#### Maxsuppression=20

| k    | Loss_Metricsum     |
| ---- | ------------------ |
| 10   | 2.0552459640316716 |
| 20   | 3.055013883930883  |
| 30   | 3.055013883930883  |
| 40   | 2.0                |
| 50   | 2.0                |

### Mondrian

| k    | Loss_Metricsum     |
| ---- | ------------------ |
| 10   | 0.2807992699392837 |
| 20   | 0.2888448951007028 |
| 30   | 0.3042713941368059 |
| 40   | 0.3140892755982232 |
| 50   | 0.329045286351722  |

## 实验反思与改进

* 个人认为将Loss_Metric各维度求和作为一个泛化表的泛化标准是不正确的，因为这样做没有考虑到各个维度的**语义**差别
  * 对于这个实验，有`age,gender,martial_status,race`几个属性，但是由于这里采取全局泛化，泛化方式之前确定，导致各个属性泛化最大高度不同。比如对于age泛化一层得到的Loss<1，但是对于race繁华一层Loss=1，这样就体现出了各个属性泛化上的语义区别
  * 我建议的方案是，计算出Loss_metric=$[x_1,x_2,x_3,x_4]$衡量一个泛化效果的最终信息损失可以采取的方法是：$totalloss=\sum_{i=1}^4 x_i\omega_i$ 。$\omega_i$是一个属性的权重，这里可以用属性i最大可以泛化的高度衡量
* Mondrian算法最终得到的泛化损失与泛化的次序有关，实际上，原本的paper采取的泛化方法是对于可以泛化的属性A,B，优先泛化范围更大的属性，比如判断表中属性A列上下界之差，以及表属性B上下界之差，选择范围更大的
  * 在我们的实验中可以观察到，后泛化的属性LM远远大于前者
* Mondrain算法采用的strict划分中位数的方式提升了它的Loss_Metric，如果能用soft divide的方法，则可以保证每个QI-cluster大致都是10个
* 无论从时间还是损失函数性能上看，局部泛化都要比全局泛化更加优越

