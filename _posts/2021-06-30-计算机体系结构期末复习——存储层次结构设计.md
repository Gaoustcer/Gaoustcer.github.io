---
layout:     post
title:      计算机体系结构期末复习——存储层次结构设计
subtitle:   计算机体系结构期末复习——存储层次结构设计
date:       2021-06-30
author:     Haihan Gao
header-img: img/post-bg-swift2.jpg
catalog: true
tags:
    - Computer Architecture
    - Course review
    - 2021 spring review
---
# 计算机体系结构期末复习——存储层次结构设计

## 基本概念

### 存储层次结构

#### 工作原理——locality

* 时间局部性
* 空间局部性

#### 基本问题

* Block 换入换出的基本单元
* 镜像和一致性问题
* 寻址
* 不同层次的cache块大小可能不同，页大小大于cache块大小 `Block Frame Address+Block Offset`

#### 性能评价

* 命中
* 失效率
* 平均访存时间=命中时间+失效率$\times$失效开销

### Cache基本结构

#### 映像规则

* 全相联——可以放在cache中任何位置
* 直接映像——$j=i\ mod \ M$ M为cache中的块数
* 组相连——N路组相连，代表一组中含有N个`cache line`
  * 根据地址**低位**判断出于哪一组
  * 放在某一组的任意位置
  * 相连度越高，cache空间利用率越高，失效率越低，cache实现越复杂

#### 组相连查找方法

* 并行查找
* 比较tag——地址高位
* index用于判断在哪一组
* Block offset用于选择block中的哪一个字
* 地址=tag+index+Block offset

![image-20210629090738540](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20210629090738540.png)

#### 替换方法

* 随机
* FIFO
* LRU

#### 写策略

* 写命中
  * 写直达——直接写回内存
  * 写回——只写回cache，不写回主存
* 写失效
  * 写分配——调入cache中，随后进行写入
  * 写不分配——直接写回下一级存储器，不调入cache
* 一般Write back - write allocate
* Write through - no-write allocate

## Cache基本优化算法

### 性能分析

* CPU time=(CPU execution clock cycles+Memory stall clock cycles)$\times$clock cycle time
* Memory stall clock cycles=(Reads x Read miss rate x Read miss penalty+Writes x Write miss rate x Write miss penalty)

### 降低失效率

* 冷启动
* 容量失效——被替换的块被重新访问
* 冲突失效——同一组被影射了太多块，导致即使存在空闲仍然被替换

#### 优化策略

* 增大cache容量
* 增大块
* 预取

#### Victim Cache

* 暂存因为冲突失效被丢弃的块
* 失效时检查victim cache中是否存在数据，如果有则从victim cache中取

### 减少失效开销

* 多级cache技术
* 读优先于写

#### 多级包容性

* 写策略
  * Write-through策略适用于L1到L2
  * Write-back策略适用于L2到更低级存储器，降低存储总线的数据传输压力
* L2的替换动作对L1可见
  * L2的一块被替换出去，L1中对应的块也要被替换进去
* L1 cache中的块总是存在于L2 cache中

#### 多级不包容

* L1 cache不会在L2 cache中
* L1到L2，L2到更低级的cache的写策略均为Write-back
* L2存储L1抛弃的块，以防后续L1还要使用

### 性能分析

* 局部失效率 该级Cache的失效次数/到达该级Cache的访存次数
* 全局失效率 该级Cache的失效次数/CPU发出的访存总次数

## Cache高级优化策略

### 缩短命中时间

* 第一级cache应当小并且简单
* 预测选中的路，预测错误导致命中时间边长

### 增大cache带宽

* 访问L1cache由多个流水段组成
  * 增大了分支预测错误的考校
  * load-use延时增加
* 非阻塞cache
  * 前一条指令访存miss，允许后一条指令接着访问cache
  * hit under miss/multiple misses
  * 乱序执行/多线程处理器
  * 增加Miss Status holding Register MSHR包含正在等待处理的失效
    * 相同的块包含多个未解决的访存失效
    * 多个未解决的块地址
  * 失效分类
    * 冷启动
    * Secondary 后续过程中的失效
    * Structural Stall miss MSHR资源耗尽
* 多端口cache
  * 控制和数据通路在cache中存在多份
  * cache组织成多个banks
  * 每个bank是一个端口
  * 可以并行访问不同的bank
  * 多体交叉编址

### 减少失效开销

* 关键字优先
  * 由于cache换入换出的单元是一个cache line，需要等待整个cache line均换入才能启动
  * 首先请求CPU需要的字，请求字一到达CPU，就继续执行，同时处理器调入其它字
* 提前重启
  * 请求字顺序保持不变
  * 请求字一旦到达CPU，就继续执行
* 合并写
  * 向写缓冲写入地址和数据，如果缓冲中存在被修改的块，就合并两次写的结果
  * 缓解写缓冲满导致的CPU stall
  * 不适用于I/O地址空间

### 降低失效率——编译器优化

* 减少指令失效——指令调度
* 减少数据失效——优化改善数据的空间局部性和时间局部性

### 并行

#### 硬件预取

* 指令预取
  * 存在控制指令导致预取失效
  * 预取的指令可以放在cache中，也可以放在其它地方
* 数据预取
* 预取利用的是**存储器的空闲带宽**

#### 编译预取

* ISA增加预取指令，让编译器控制预取
* 分类
  * 寄存器预取——数据取到寄存器中
  * cache预取——只将数据取到cache中，不放入寄存器