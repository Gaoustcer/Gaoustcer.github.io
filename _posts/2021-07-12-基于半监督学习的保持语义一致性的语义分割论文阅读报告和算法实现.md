---
layout:     post
title:      基于半监督学习的保持语义一致性的语义分割论文阅读报告和算法实现
subtitle:   基于半监督学习的保持语义一致性的语义分割论文阅读报告和算法实现
date:       2021-07-12
author:     Haihan Gao
header-img: img/post-bg-swift2.jpg
catalog: true
tags:
    - Research
    - semi-supervised learning
---
# 基于半监督学习的保持语义一致性的语义分割论文阅读报告和算法实现

## 论文阅读

### 主要驱动

* 语义分割中，获得大量标注数据集是不可能的
* 基于小范围标注数据集的模型学习，可能导致学习模型过于依赖图像中物体的环境而不是本身作为语义分割的标准，容易导致泛化误差较大
* 提出半监督学习的方法解决这个问题，主要通过恰当的图像增广技术
* 理想的语义分割模型仅仅依赖于单个像素的RGB像素本身作为判断其label的标准，这样是为了保持模型判别的语义一致性(`Context-aware Consistency`)，但是，语义分割不依赖上下文信息是不可能的，少量的训练样本导致模型过度依赖于图像的语义信息，我们的目标是通过无监督学习避免模型过度利用上下文信息
* 当前的成功语义分割模型成功支持在于能够合适地聚集图片中的语义线索，进而进行最终的预测

### 主要创新点

* 对无监督图像进行适当的裁剪，同一幅图像上不同的裁剪存在重叠的部分，可以认为重叠的部分存在于不同的语义环境中
* 我们不知道真实的标签(针对无监督学习的样本)，但是针对重叠部分的特征信息应当被保持
* 为了衡量这种一致性，论文提出了一种损失函数，称为`Directional Contrastive Loss`

#### 对比损失

常见的分类问题最终采用的是交叉熵损失，在最后一层增加一个`Linear layer+softmax`，得到概率分布，带入(1)中计算一个损失
$$
L_{CE}=-\sum_c I(y_i=c)\log{P(y=c|X_i)}\tag{1}
$$
但是这种损失函数是基于已知标签的训练样本，对于没有标签的无监督学习，我们的基本假设是相似的输入产生的样本是相似的，比如对于图像识别任务，我们已经有了一个原始图片$X_i$，对其做变换$A(X_i),B(X_i)$，我们希望变换后的$A(X_i),B(X_i)$之间的特征距离要小于$A(X_i)$和其它任意图片$X_j$之间的距离，即满足(2)
$$
dist(A(X_i),B(X_i))<<dist(A(X_i),X_{j\neq i})\tag{2}
$$

#### Directional Contrastive Loss

假设重叠部分为$\phi_{o1},\phi_{o2}$，衡量两者相似度的方法主要是基于在像素层次上的对比学习，保证尽量多的像素属于同一类别，尽量少的像素属于不同类别，规定以下记号
$$
\phi_{o1}^{h,w}
$$
表示重叠部分的第$h,w$个像素
$$
f_{o1}^{h,w}
$$
代表模型预测这个像素属于哪一类，则第b个无标签样本的DC loss $\mathcal{L}_{dc}^b$表示如下
$$
l_{dc}^b(\phi_{o1},\phi_{o2})=-\frac{1}{N}\sum_{h,w}\mathcal{M}_d^{h,w}\log{\frac{r(\phi_{o1}^{h,w},\phi_{o2}^{h,w})}{r(\phi_{o1}^{h,w},\phi_{o2}^{h,w})+\sum_{\phi_n\in \mathcal{F}_n}r(\phi_{o1}^{h,w},\phi_{n})}}\\
\mathcal{M}_d^{h,w}=1\{max\mathcal{C}(f_{o1}^{h,w})< max\mathcal{C}(f_{o2}^{h,w})\}\\
\mathcal{L}_{dc}^b=l_{dc}^b(\phi_{o1}^{h,w},\phi_{o2}^{h,w})+l_{dc}^b(\phi_{o2}^{h,w},\phi_{o1}^{h,w})\tag{3}
$$

* 论文中提到了`more nagative samples lead to better performance`，因此选择负样本不仅来自于原来这张图片，还来自这个训练batch中的其它图片
* 维护一个memory bank，保存过去几个batches的特征

### 采样策略

目标识别中谈到的一个重要概念上Anchor，传统的目标检测问题的方法是使用**滑动窗口**，所有装口共享一个判别器，不同尺度的窗口在图像中顺次滑动，判别器判断窗口内的目标是什么，最终综合所有窗口的判别结果做一些后处理，就可以找到目标在哪里，并且得到每个目标的类别信息。

深度学习中，这个滑动窗口被称为anchor-box，anchor的作用是用来固定**滑动窗口**，表示box的中心，anchor-box的提出主要是为了解决目标框定位的问题。

事先在图像中选择多个像素，作为anchor的锚点，目标检测转化为寻找目标位置相对于anchor锚点的偏移。

anchor的描述有两个参数，scale和ratio，描述尺寸和长宽比。根据这两个参数的获得方式，可以分成人工设计的anchor，学习得到的anchor